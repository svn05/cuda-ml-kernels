{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA ML Kernels — Build, Test & Benchmark\n",
    "\n",
    "**Runtime → Change runtime type → T4 GPU** before running.\n",
    "\n",
    "This notebook clones the repo, builds the CUDA extension, runs all tests, and benchmarks against PyTorch native ops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU is available\n",
    "!nvidia-smi\n",
    "import torch\n",
    "print(f\"\\nPyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.version.cuda}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repo and install\n",
    "!git clone https://github.com/svn05/cuda-ml-kernels.git\n",
    "%cd cuda-ml-kernels\n",
    "!pip install -e . --no-build-isolation 2>&1 | tail -5\n",
    "print(\"\\n✅ Build complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all tests\n",
    "!pip install pytest -q\n",
    "!python -m pytest tests/ -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run benchmarks\n",
    "!pip install tabulate -q\n",
    "!python benchmarks/benchmark.py --sizes 256 512 1024 2048 4096 --warmup 20 --runs 50"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
